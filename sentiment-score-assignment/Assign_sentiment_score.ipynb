{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CysP6lAyjWf"
      },
      "outputs": [],
      "source": [
        "# Task:\n",
        "# 1. load the best model (highest accuracy on test data)\n",
        "# 2. load the raw data and preprocess it\n",
        "# 3. apply the loaded classifier to assign sentiment score\n",
        "# 4. save the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n"
      ],
      "metadata": {
        "id": "pLdlufjUzX0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1: Load the best model (highest accuracy on test data)\n",
        "# Assuming the best model is saved as 'best_model.h5'\n",
        "best_model_path = 'saved_models/RNN.h5'\n",
        "model = load_model(best_model_path)\n",
        "print(\"Model loaded successfully.\")\n"
      ],
      "metadata": {
        "id": "5cugYkgr79rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Load the raw data and preprocess it\n",
        "\n",
        "# Load data\n",
        "data_path = 'data/twitter_processed_data.csv'\n",
        "twitter_data = pd.read_csv(data_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Preprocess the raw data\n",
        "# Tokenization and padding (Assuming a max sequence length of 100)\n",
        "max_seq_length = 100\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(twitter_data['text'])\n",
        "sequences = tokenizer.texts_to_sequences(twitter_data['text'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_seq_length)\n",
        "\n"
      ],
      "metadata": {
        "id": "K47yv_U935tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3: Apply the loaded classifier to assign sentiment score\n",
        "# Assuming the model outputs probabilities for binary classification (e.g., positive/negative sentiment)\n",
        "sentiment_scores = model.predict(padded_sequences)\n",
        "raw_data['sentiment_score'] = sentiment_scores\n",
        "\n",
        "# If your model has more than two classes, you might need to decode the predictions\n",
        "# For example:\n",
        "# label_encoder = LabelEncoder()\n",
        "# label_encoder.classes_ = np.load('path_to_your_label_classes.npy')\n",
        "# raw_data['sentiment'] = label_encoder.inverse_transform(np.argmax(sentiment_scores, axis=1))\n",
        "\n"
      ],
      "metadata": {
        "id": "eM0RXO4r37rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4: Save the data\n",
        "# Save the data with sentiment scores to a new CSV file\n",
        "output_data_path = 'path_to_your_output/sentiment_scored_data.csv'\n",
        "raw_data.to_csv(output_data_path, index=False)\n",
        "print(\"Data saved successfully.\")"
      ],
      "metadata": {
        "id": "HU42ilJS38am"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}